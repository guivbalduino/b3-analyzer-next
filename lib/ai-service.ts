import { GoogleGenerativeAI } from "@google/generative-ai";
import { getCerebrasModels, generateCerebrasAnalysis } from "./cerebras-service";
import { getGroqModels, generateGroqAnalysis } from "./groq-service";

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

interface AIModel {
    id: string;
    name: string;
    provider: string;
}

export async function listAvailableModels() {
    const apiKey = process.env.GEMINI_API_KEY;
    const cerebrasKey = process.env.CEREBRAS_API_KEY;
    const groqKey = process.env.GROQ_API_KEY;

    let geminiModels: AIModel[] = [];
    let cerebrasModels: AIModel[] = [];
    let groqModels: AIModel[] = [];

    // 1. Fetch Gemini Models
    if (apiKey) {
        try {
            const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`);
            const data = await response.json();

            if (data.models) {
                geminiModels = data.models
                    .filter((m: any) =>
                        m.supportedGenerationMethods.includes('generateContent') &&
                        m.name.includes('gemini') &&
                        !m.name.includes('vision') &&
                        !m.name.includes('audio') &&
                        !m.name.includes('tts') &&
                        !m.name.includes('imaging') &&
                        !m.name.includes('experimental') &&
                        !m.name.includes('nano') &&
                        !m.name.includes('preview')
                    )
                    .map((m: any) => ({
                        id: m.name.replace('models/', ''),
                        name: m.displayName,
                        provider: "Google"
                    }))
                    .sort((a: any, b: any) => a.name.localeCompare(b.name));
            }
        } catch (error) {
            console.error("Error listing Gemini models:", error);
            geminiModels = [
                { id: "gemini-2.5-flash-lite", name: "Gemini 2.5 Flash Lite", provider: "Google" },
                { id: "gemini-1.5-flash", name: "Gemini 1.5 Flash", provider: "Google" },
            ];
        }
    }

    // 2. Fetch Cerebras Models
    if (cerebrasKey) {
        try {
            cerebrasModels = await getCerebrasModels();
        } catch (error) {
            console.error("Error listing Cerebras models:", error);
        }
    }

    // 3. Fetch Groq Models
    if (groqKey) {
        try {
            groqModels = await getGroqModels();
        } catch (error) {
            console.error("Error listing Groq models:", error);
        }
    }

    // Combine and return
    return [...geminiModels, ...cerebrasModels, ...groqModels];
}

export async function generateStockAnalysis(
    symbol: string,
    priceData: any,
    historicalData: any[],
    newsData: any[],
    modelName: string = "gemini-2.5-flash-lite",
    analysisType: string = "completa"
) {
    // Format data into XML for better LLM parsing
    const historicalXml = historicalData.map(d => `
    <record>
        <date>${new Date(d.date).toLocaleDateString('pt-BR')}</date>
        <close>${d.close}</close>
        ${d.dividend ? `<dividend>${d.dividend}</dividend>` : ''}
    </record>`).join('');

    const newsXml = newsData.map(n => `
    <news>
        <title>${n.title}</title>
        <publisher>${n.publisher}</publisher>
        <sentiment>${n.sentiment}</sentiment>
        <date>${new Date(n.providerPublishTime).toLocaleDateString('pt-BR')}</date>
    </news>`).join('');

    const baseContext = `
Aja como um analista financeiro sÃªnior certificado (CNPI) e gestor de portfÃ³lio especializado no mercado brasileiro (B3).
Sua tarefa Ã© gerar um relatÃ³rio de anÃ¡lise para o ativo ${symbol} com base nos dados abaixo:

<current_price>
    <symbol>${symbol}</symbol>
    <price>${priceData.price}</price>
    <change_percent>${priceData.changePercent}</change_percent>
    <name>${priceData.name}</name>
</current_price>

<historical_data>
    ${historicalXml}
</historical_data>

<latest_news>
    ${newsXml}
</latest_news>
`;

    const prompts: Record<string, string> = {
        completa: `
${baseContext}
Gere uma **ANÃLISE ESTRATÃ‰GICA COMPLETA** "PREMIUM".
Estrutura ObrigatÃ³ria:
- # ğŸ’ AnÃ¡lise EstratÃ©gica: ${symbol} - ${priceData.name}
- ## ğŸ“Š Panorama Atual: Resumo executivo do preÃ§o e variaÃ§Ã£o.
- ## ğŸ“ˆ AnÃ¡lise de TendÃªncia (2 Anos): Comente suporte, resistÃªncia e padrÃµes.
- ## ğŸ“° Sentimento & NotÃ­cias: Impacto das notÃ­cias recentes.
- ## ğŸ¯ Veredito & Perspectivas: Escala [FORTE COMPRA Ã  FORTE VENDA].
- ## ğŸ›¡ï¸ Riscos: 2-3 pontos de atenÃ§Ã£o.
`,
        tecnica: `
${baseContext}
Gere uma **ANÃLISE TÃ‰CNICA DETALHADA**.
Foque exclusivamente em:
- # ğŸ“ˆ AnÃ¡lise TÃ©cnica: ${symbol}
- ## ğŸ“‰ MovimentaÃ§Ã£o de PreÃ§o: Analise as variaÃ§Ãµes nos Ãºltimos 2 anos.
- ## ğŸ§± Suportes e ResistÃªncias: Identifique nÃ­veis crÃ­ticos de preÃ§o.
- ## ğŸ”„ TendÃªncia: Defina se a tendÃªncia Ã© de Alta, Baixa ou Lateral.
- ## â±ï¸ Timing de Entrada: Melhor momento tÃ©cnico para operaÃ§Ã£o.
Use terminologia tÃ©cnica (MÃ©dias MÃ³veis, IFR/RSI se possÃ­vel deduzir, PadrÃµes de Candlestick).
`,
        fundamentalista: `
${baseContext}
Gere uma **ANÃLISE FUNDAMENTALISTA & CONTEXTO**.
Foque em:
- # ğŸ¦ AnÃ¡lise Fundamentalista: ${symbol}
- ## ğŸ¢ Sobre a Empresa: Perfil e setor de atuaÃ§Ã£o.
- ## ğŸ’° AvaliaÃ§Ã£o de PreÃ§o: O valor atual parece justo perante o histÃ³rico?
- ## ğŸ“Š Dividendos & Proventos: Analise o histÃ³rico de distribuiÃ§Ã£o presente nos dados.
- ## ğŸš€ Perspectivas de Longo Prazo: O ativo Ã© resiliente?
`,
        dividendos: `
${baseContext}
Gere um **RELATÃ“RIO DE DIVIDENDOS (YIELD FOCUS)**.
Foque em:
- # ğŸ’° RelatÃ³rio de Dividendos: ${symbol}
- ## ğŸ—“ï¸ HistÃ³rico de Pagamentos: Regularidade e valores.
- ## ğŸ“‰ Dividend Yield: Estimativa baseada no preÃ§o atual ${priceData.price}.
- ## âš–ï¸ Sustentabilidade: O preÃ§o atual permite um bom Yield Futuro?
- ## ğŸ ConclusÃ£o: Ã‰ uma boa "Vaca Leiteira" para o portfÃ³lio?
`,
        sentimento: `
${baseContext}
Gere um **RELATÃ“RIO DE SENTIMENTO & NEWSFLOW**.
Foque em:
- # ğŸ“° TermÃ´metro do Mercado: ${symbol}
- ## ğŸš¨ NotÃ­cias de Impacto: Analise as manchetes fornecidas.
- ## ğŸ“‰ ReaÃ§Ã£o do PreÃ§o: Como o preÃ§o reagiu Ã s Ãºltimas notÃ­cias enviadas?
- ## ğŸ—£ï¸ Buzz do Mercado: O sentimento geral Ã© de pÃ¢nico, euforia ou cautela?
- ## âš¡ Alerta de Curto Prazo: O que esperar para os prÃ³ximos dias?
`
    };

    const finalPrompt = (prompts[analysisType] || prompts.completa) + `
---
### INSTRUÃ‡Ã•ES CRÃTICAS DE FORMATAÃ‡ÃƒO:
1. **Markdown rico** e **Emojis** pertinentes.
2. Tom **Profissional** e **AnalÃ­tico**.
3. **NÃƒO ADICIONE ADVERTÃŠNCIAS OU DISCLAIMERS** (ex: "Isso nÃ£o Ã© uma recomendaÃ§Ã£o..."). JÃ¡ temos um disclaimer padrÃ£o no sistema. 
4. Responda em PortuguÃªs do Brasil.
5. NÃ£o adicione intros vazias. Comece direto no tÃ­tulo.
`;

    // ROUTE REQUEST based on modelName
    if (modelName.startsWith("gemini-")) {
        // Google Gemini Direct
        if (!process.env.GEMINI_API_KEY) {
            throw new Error("GEMINI_API_KEY nÃ£o configurada no servidor.");
        }
        const model = genAI.getGenerativeModel({ model: modelName });
        const result = await model.generateContent(finalPrompt);
        const response = await result.response;
        return response.text();
    } else if (modelName.includes("llama") || modelName.includes("mixtral") || modelName.includes("gemma")) {
        // Determine if it's Groq or Cerebras
        // Usually Groq models in our fetch have specific IDs. 
        // Let's check for CEREBRAS specifically if it's 'gpt-oss' or if it matches cerebras list.
        // For simplicity, we can look at the provider from the listAvailableModels but here we only have the modelName.

        // Strategy: Try Groq for llama/mixtral if key is present, fallback to Cerebras if appropriate or specific IDs.
        if (modelName === "gpt-oss-120b" || modelName.startsWith("zai-") || modelName.includes("qwen")) {
            return await generateCerebrasAnalysis(modelName, finalPrompt);
        }

        // Preferred fast provider for Llama/Mixtral: Groq
        if (process.env.GROQ_API_KEY) {
            return await generateGroqAnalysis(modelName, finalPrompt);
        }

        // Fallback to Cerebras if Groq key missing
        return await generateCerebrasAnalysis(modelName, finalPrompt);
    } else {
        // Fallback or explicit Cerebras
        return await generateCerebrasAnalysis(modelName, finalPrompt);
    }
}
